# SIGIR26 (Demo Repository)

This repository provides a **minimal, review-stage demo** for our SIGIR 2026 short-paper submission:

**â€œSpectral Drift Monitoring of Contextual Embeddings for Multi-Sense Semantic Changeâ€**

> **Review-stage note.**  
> To support an *open-science* signal during the anonymous review period, we release a lightweight demo that reflects the **overall pipeline and code structure**.  
> A **full, cleaned, and fully reproducible release** (complete configs/scripts, end-to-end runs, and documentation) will be provided **after acceptance**.

---

## ğŸ§  Overview

Detecting how word meanings shift over time is essential to understanding language, technology, and society.  
Our work introduces an **unsupervised semantic drift monitor** for contextual embeddings (e.g., BERT-family models) with an emphasis on **multi-sense** change and **interpretability**.

At a high level, the approach:
- adopts a distributional view of contextual representations (projected-Gaussian perspective),
- monitors drift using a **covariance-spectrum (spectral) signal**,
- supports interpretation via **multi-sense clustering** and **representative instance extraction**.

---

## âœ… What This Demo Provides

- A compact reference implementation of the main components (structure-level faithful to the paper):
  - embedding IO and slice handling,
  - spectral drift scoring utilities,
  - optional clustering hooks for multi-sense analysis,
  - qualitative inspection utilities (representative usages).

### Not included (yet)
- End-to-end reproduction scripts and exact hyperparameter/config files
- Preprocessed datasets and embedding caches
- Full ablation, logging, and figure/table generation pipeline

These will be released in the post-acceptance version.

---

## ğŸ“ Repository Structure

<pre>
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ detect_semantic_change.py         # Drift monitor demo (reference pipeline)
â”‚   â”œâ”€â”€ util.py                           # Utility functions for data loading, clustering, etc.
â”‚   â”œâ”€â”€ visualize_change_target_word.py   # Clustering + PCA projection for interpretability
â”‚   â”œâ”€â”€ extract_typical_instance.py       # Highlighting representative shifted usages
â”‚   â””â”€â”€ patent_preprocess.py              # Tools for cleaning and processing USPTO patent texts
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data_description.pdf              # Overview of benchmark & domain datasets
â”‚   â””â”€â”€ additional_resources/             # Custom stopword lists, Greek symbols, and filters for USPTO
â”‚       â”œâ”€â”€ greek.txt
â”‚       â”œâ”€â”€ stopwords.txt
â”‚       â””â”€â”€ symbols.txt
</pre>


---

## ğŸ“Š Datasets

### ğŸ”¬ SemEval-2020 Task 1
- Multilingual benchmark with human-labeled semantic shifts (EN, DE, LA, SV).
- Evaluated using mBERT contextual embeddings.

### ğŸ›ï¸ USPTO Patent Corpus
- 7.6M granted patents (1960â€“2022), segmented into 5-year windows.
- Tracks how technical terms evolve in meaning and domain usage.
- Demonstrates real-world scalability and interpretability.
